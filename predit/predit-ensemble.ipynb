{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    RobertaForSequenceClassification,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubmitGenerator(prediction, sampleFile, filename=\"prediction.csv\", public=True):\n",
    "    sample = pd.read_csv(sampleFile)\n",
    "    submit = {}\n",
    "    submit[\"order_id\"] = list(sample.order_id.values)\n",
    "    redundant = len(sample) - prediction.shape[0]\n",
    "    if public:\n",
    "        submit[\"BACKGROUND\"] = list(prediction[:,0]) + [0]*redundant\n",
    "        submit[\"OBJECTIVES\"] = list(prediction[:,1]) + [0]*redundant\n",
    "        submit[\"METHODS\"] = list(prediction[:,2]) + [0]*redundant\n",
    "        submit[\"RESULTS\"] = list(prediction[:,3]) + [0]*redundant\n",
    "        submit[\"CONCLUSIONS\"] = list(prediction[:,4]) + [0]*redundant\n",
    "        submit[\"OTHERS\"] = list(prediction[:,5]) + [0]*redundant\n",
    "    else:\n",
    "        submit[\"BACKGROUND\"] = [0]*redundant + list(prediction[:,0])\n",
    "        submit[\"OBJECTIVES\"] = [0]*redundant + list(prediction[:,1])\n",
    "        submit[\"METHODS\"] = [0]*redundant + list(prediction[:,2])\n",
    "        submit[\"RESULTS\"] = [0]*redundant + list(prediction[:,3])\n",
    "        submit[\"CONCLUSIONS\"] = [0]*redundant + list(prediction[:,4])\n",
    "        submit[\"OTHERS\"] = [0]*redundant + list(prediction[:,5])\n",
    "    df = pd.DataFrame.from_dict(submit) \n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_all_zero_problems(origin_predict):\n",
    "    correct_predict = []\n",
    "    count_of_zps = 0\n",
    "    for row in origin_predict:\n",
    "        one_hot = (row > 0.5).type(torch.IntTensor)\n",
    "        if torch.sum(one_hot) > 0:\n",
    "             correct_one_hot = one_hot\n",
    "        else:\n",
    "            # let best score to 1\n",
    "            new_threadhold = torch.max(row)\n",
    "            correct_one_hot = (row >= new_threadhold).type(torch.IntTensor)\n",
    "            count_of_zps += 1\n",
    "        correct_predict.append(correct_one_hot.unsqueeze(0))\n",
    "    \n",
    "    correct_predict = torch.cat(correct_predict).detach().numpy()\n",
    "    assert correct_predict.shape == origin_predict.shape\n",
    "    print(\"{} zero-problems is corrected\".format(count_of_zps))\n",
    "    return correct_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.features[idx]\n",
    "        \n",
    "        return (\n",
    "            feature[\"abstract_id\"], # ignore\n",
    "            feature[\"seq_id\"],      # ignore\n",
    "            torch.tensor(feature[\"net_inputs\"][\"input_ids\"]),        \n",
    "            torch.tensor(feature[\"net_inputs\"][\"attention_mask\"]),\n",
    "            torch.tensor(feature[\"net_inputs\"][\"token_type_ids\"])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predit(model, dataloader, use_cuda=True, use_fp16=True):\n",
    "    if use_fp16:\n",
    "        model.half()\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    for batch in tqdm(test_dataloader, desc=\"predict:\"):\n",
    "        with torch.no_grad():\n",
    "            net_input_batch = batch[2:]\n",
    "            input_ids, attention_mask, token_type_ids = [i.to(\"cuda\") for i in net_input_batch]\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "            soft_logits = torch.sigmoid(logits)\n",
    "            prediction.append(soft_logits.to(\"cpu\"))\n",
    "    prediction = torch.cat(prediction).detach()\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = torch.load(\"data_bin/private-test_roberta-large_v2.pt\")\n",
    "test_dataset = TestDataset(test_features)\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                             batch_size=512*4,\n",
    "                             shuffle=False,\n",
    "                             num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_checkpoints = [\n",
    "    \"checkpoint/roberta-large-best\",\n",
    "    \"checkpoint/roberta-large-kaverage\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_logits = []\n",
    "for path in ensemble_checkpoints:\n",
    "    model = RobertaForSequenceClassification.from_pretrained(path)\n",
    "    model = nn.DataParallel(model)\n",
    "    soft_logits = predit(model, test_dataloader, use_fp16=False)\n",
    "    total_logits.append(soft_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "final_predict = alpha * total_logits[0] + (1-alpha) * total_logits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = correct_all_zero_problems(final_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubmitGenerator(prediction, \n",
    "                \"datas/task1_sample_submission.csv\",\n",
    "                \"results/mix_best-kaverage_fixzp_private.csv\",\n",
    "                public=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
